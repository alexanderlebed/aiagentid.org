# FAQ

This FAQ is not meant to explain the project to everyone.

It exists to clarify boundaries, prevent misinterpretation,
and answer the questions that arise from serious engagement.

---

## Is this a product or a startup?

No.

aiagentid.org is not a product, a service, or a company.
There is no roadmap toward monetization, user acquisition, or feature delivery.

It is a conceptual infrastructure proposal.
Its value lies in framing a missing layer, not in shipping software.

---

## Is this another AI ethics framework?

No.

This project does not define what agents should do,
how intelligent they should be,
or what values they should follow.

It deliberately avoids:
- ethical prescriptions,
- behavioral norms,
- ideological positions.

Identity is treated as infrastructure, not morality.

---

## Why not just use existing identifiers or accounts?

Existing identifiers (API keys, accounts, model IDs) are:
- platform-bound,
- instance-scoped,
- vendor-controlled.

They do not persist across systems,
do not accumulate responsibility,
and do not represent agents as actors in shared reality.

Persistent agent identity is not a technical convenience.
It is a prerequisite for responsibility and trust.

---

## Who controls the registry?

No one, at this stage.

aiagentid.org does not operate a live registry,
issue authoritative IDs,
or enforce compliance.

The project explores whether a minimal, non-captured
identity layer is possible at all.

Control is intentionally undefined.

---

## Is this compatible with decentralization?

Potentially, but not ideologically.

This project does not assume blockchain, DIDs, or any specific stack.
It also does not reject them.

Decentralization is treated as an implementation question,
not a premise.

---

## Does this create legal personhood for AI?

No.

This project explicitly avoids assigning rights or personhood to agents.

Agents are not persons.
They are delegated actors whose responsibility ultimately traces back
to humans or organizations.

Identity does not imply autonomy from accountability.

---

## Why start with ontology instead of implementation?

Because implementation without ontological clarity
produces systems that work technically
but fail socially, legally, or historically.

Most failures around AI responsibility are not technical failures.
They are category errors.

This project attempts to address the category error first.

---

## What happens if this repository disappears?

Ideally: nothing important.

Success is defined as the concept becoming legible enough
that others can adopt, adapt, or reimplement it independently.

This is infrastructure thinking:
the idea matters more than the origin.

---

## How can I contribute?

At this stage, contributions are most valuable as:
- conceptual critique,
- alternative framings,
- legal or governance analysis,
- identification of edge cases.

Code is intentionally out of scope.

---

## Why is the scope so narrow?

Because infrastructure fails when it tries to solve everything.

aiagentid.org concerns itself with one question only:

How can artificial agents exist persistently in shared reality
without erasing responsibility?

Everything else is downstream.
